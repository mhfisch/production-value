{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(<HDF5 file \"TRAAAAW128F429D538.h5\" (mode r+)>)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "filename = 'data/A/A/A/TRAAAAW128F429D538.h5'\n",
    "f = h5py.File(filename, 'r')\n",
    "\n",
    "# List all groups\n",
    "print(\"Keys: %s\" % f.keys())\n",
    "a_group_key = list(f.keys())[0]\n",
    "\n",
    "# Get the data\n",
    "data = list(f[a_group_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f['analysis']) == h5py._hl.dataset.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def h5_to_dict(f):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    f: an opened HDF5 file\n",
    "    \n",
    "    output:\n",
    "    dict_f: The HDF5 file in a python dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    d = defaultdict(dict)\n",
    "    for key in list(f.keys()):\n",
    "        if type(f[key]) != h5py._hl.dataset.Dataset:\n",
    "            for subitem in key:\n",
    "                d[key][subitem] = f[key][subitem]\n",
    "        else:\n",
    "            d[key] = f[key]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'a' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5705c1034bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-761049940323>\u001b[0m in \u001b[0;36mh5_to_dict\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msubitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'a' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "h5_to_dict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f['analysis']['songs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array() missing required argument 'object' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-4b95915cdf56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: array() missing required argument 'object' (pos 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ar = np.array()\n",
    "a.read_direct(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22050, b'a222795e07cd65b7a530f1346f520649', 0., 218.93179, 0.247, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.736, -11.197, 0, 0.636, 218.932, 92.198, 4, 0.778, b'TRAAAAW128F429D538')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(d[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis\n",
      "bars_confidence\n",
      "bars_start\n",
      "beats_confidence\n",
      "beats_start\n",
      "sections_confidence\n",
      "sections_start\n",
      "segments_confidence\n",
      "segments_loudness_max\n",
      "segments_loudness_max_time\n",
      "segments_loudness_start\n",
      "segments_pitches\n",
      "segments_start\n",
      "segments_timbre\n",
      "songs\n",
      "tatums_confidence\n",
      "tatums_start\n",
      "metadata\n",
      "artist_terms\n",
      "artist_terms_freq\n",
      "artist_terms_weight\n",
      "similar_artists\n",
      "songs\n",
      "musicbrainz\n",
      "artist_mbtags\n",
      "artist_mbtags_count\n",
      "songs\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(dict)\n",
    "for key in list(f.keys()):\n",
    "    print (key)\n",
    "    d[key] = defaultdict(dict)\n",
    "    for key2 in list(f[key]):\n",
    "        print (key2)\n",
    "        d[key][key2] = list(f[key][key2])\n",
    "        for i, item in enumerate(d[key][key2]):\n",
    "            if type(item) == np.bytes_:\n",
    "                d[key][key2][i] = d[key][key2][i].decode()\n",
    "#             if type(item) == np.void:\n",
    "#                 for j, entry in enumerate(item):\n",
    "#                     if type(entry) == np.bytes_:\n",
    "#                         d[key][key2][i][j] = d[key][key2][i][j].decode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_to_dict(f):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        f: opened .h5 file from MSDS\n",
    "    output:\n",
    "        d: a dictionary version of the .h5 file\n",
    "    \"\"\"\n",
    "    for key in list(f.keys()):\n",
    "#     print (key)\n",
    "        d[key] = defaultdict(dict)\n",
    "        for key2 in list(f[key]):\n",
    "#             print (key2)\n",
    "            d[key][key2] = list(f[key][key2])\n",
    "            for i, item in enumerate(d[key][key2]):\n",
    "                if type(item) == np.bytes_:\n",
    "                    d[key][key2][i] = d[key][key2][i].decode()\n",
    "    #             if type(item) == np.void:\n",
    "    #                 for j, entry in enumerate(item):\n",
    "    #                     if type(entry) == np.bytes_:\n",
    "    #                         d[key][key2][i][j] = d[key][key2][i][j].decode()\n",
    "    return d\n",
    "\n",
    "def multi_indexer(d):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        d: a MSDS dictionary from h5_to_dict()\n",
    "    output:\n",
    "        multi_index_dict: a multi-indexed dictionary compatible with Pandas DataFrames\n",
    "    \"\"\"\n",
    "    multi_index_dict = {}\n",
    "    for i, key in enumerate (d.keys()):\n",
    "        for j, key2 in enumerate(d[key].keys()):\n",
    "            multi_index_dict[(key,key2)] = [d[key][key2]]\n",
    "    return multi_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"13\" halign=\"left\">analysis</th>\n",
       "      <th colspan=\"5\" halign=\"left\">metadata</th>\n",
       "      <th colspan=\"3\" halign=\"left\">musicbrainz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bars_confidence</th>\n",
       "      <th>bars_start</th>\n",
       "      <th>beats_confidence</th>\n",
       "      <th>beats_start</th>\n",
       "      <th>sections_confidence</th>\n",
       "      <th>sections_start</th>\n",
       "      <th>segments_confidence</th>\n",
       "      <th>segments_loudness_max</th>\n",
       "      <th>segments_loudness_max_time</th>\n",
       "      <th>segments_loudness_start</th>\n",
       "      <th>...</th>\n",
       "      <th>tatums_confidence</th>\n",
       "      <th>tatums_start</th>\n",
       "      <th>artist_terms</th>\n",
       "      <th>artist_terms_freq</th>\n",
       "      <th>artist_terms_weight</th>\n",
       "      <th>similar_artists</th>\n",
       "      <th>songs</th>\n",
       "      <th>artist_mbtags</th>\n",
       "      <th>artist_mbtags_count</th>\n",
       "      <th>songs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0.4...</td>\n",
       "      <td>[0.58521, 2.94247, 5.14371, 7.74554, 10.36149,...</td>\n",
       "      <td>[0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.62...</td>\n",
       "      <td>[0.58521, 1.19196, 1.78893, 2.37813, 2.94247, ...</td>\n",
       "      <td>[1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373, ...</td>\n",
       "      <td>[0.0, 7.74554, 36.44331, 43.61667, 75.17954, 9...</td>\n",
       "      <td>[0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1.0...</td>\n",
       "      <td>[-60.0, -31.646, -34.565, -38.407, -34.696, -2...</td>\n",
       "      <td>[0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.073...</td>\n",
       "      <td>[-60.0, -60.0, -40.84, -40.401, -38.456, -39.6...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0.4...</td>\n",
       "      <td>[0.28519, 0.58521, 0.89422, 1.19196, 1.49119, ...</td>\n",
       "      <td>[hip hop, underground rap, g funk, alternative...</td>\n",
       "      <td>[1.0, 0.7761362332679642, 0.7296697949672141, ...</td>\n",
       "      <td>[1.0, 0.8979359555142553, 0.8842618474718359, ...</td>\n",
       "      <td>[ARV4KO21187FB38008, ARWHM281187FB3D381, ARJGO...</td>\n",
       "      <td>[[b'', 165270, 0.5817937658450281, 0.401997543...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            analysis  \\\n",
       "                                     bars_confidence   \n",
       "0  [0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0.4...   \n",
       "\n",
       "                                                      \\\n",
       "                                          bars_start   \n",
       "0  [0.58521, 2.94247, 5.14371, 7.74554, 10.36149,...   \n",
       "\n",
       "                                                      \\\n",
       "                                    beats_confidence   \n",
       "0  [0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.62...   \n",
       "\n",
       "                                                      \\\n",
       "                                         beats_start   \n",
       "0  [0.58521, 1.19196, 1.78893, 2.37813, 2.94247, ...   \n",
       "\n",
       "                                                      \\\n",
       "                                 sections_confidence   \n",
       "0  [1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373, ...   \n",
       "\n",
       "                                                      \\\n",
       "                                      sections_start   \n",
       "0  [0.0, 7.74554, 36.44331, 43.61667, 75.17954, 9...   \n",
       "\n",
       "                                                      \\\n",
       "                                 segments_confidence   \n",
       "0  [0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1.0...   \n",
       "\n",
       "                                                      \\\n",
       "                               segments_loudness_max   \n",
       "0  [-60.0, -31.646, -34.565, -38.407, -34.696, -2...   \n",
       "\n",
       "                                                      \\\n",
       "                          segments_loudness_max_time   \n",
       "0  [0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.073...   \n",
       "\n",
       "                                                      ...  \\\n",
       "                             segments_loudness_start  ...   \n",
       "0  [-60.0, -60.0, -40.84, -40.401, -38.456, -39.6...  ...   \n",
       "\n",
       "                                                      \\\n",
       "                                   tatums_confidence   \n",
       "0  [0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0.4...   \n",
       "\n",
       "                                                      \\\n",
       "                                        tatums_start   \n",
       "0  [0.28519, 0.58521, 0.89422, 1.19196, 1.49119, ...   \n",
       "\n",
       "                                            metadata  \\\n",
       "                                        artist_terms   \n",
       "0  [hip hop, underground rap, g funk, alternative...   \n",
       "\n",
       "                                                      \\\n",
       "                                   artist_terms_freq   \n",
       "0  [1.0, 0.7761362332679642, 0.7296697949672141, ...   \n",
       "\n",
       "                                                      \\\n",
       "                                 artist_terms_weight   \n",
       "0  [1.0, 0.8979359555142553, 0.8842618474718359, ...   \n",
       "\n",
       "                                                      \\\n",
       "                                     similar_artists   \n",
       "0  [ARV4KO21187FB38008, ARWHM281187FB3D381, ARJGO...   \n",
       "\n",
       "                                                       musicbrainz  \\\n",
       "                                               songs artist_mbtags   \n",
       "0  [[b'', 165270, 0.5817937658450281, 0.401997543...            []   \n",
       "\n",
       "                                 \n",
       "  artist_mbtags_count     songs  \n",
       "0                  []  [[0, 0]]  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(multi_indexer(h5_to_dict(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['analysis']['songs'][0][1] = d['analysis']['songs'][0][1].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'', 165270, 0.58179377, 0.40199754, b'ARD7TVE1187B99BFB1', nan, b'California - LA', nan, b'e77e51a5-4761-45b3-9847-2051f811e366', b'Casual', 4479, b'', 0, 0, b'Fear Itself', 300848, 0.60211999, b'SOMZWCG12A8C13C480', b\"I Didn't Mean To\", 3401791)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['metadata']['songs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('analyzer_version', 'S32'), ('artist_7digitalid', '<i4'), ('artist_familiarity', '<f8'), ('artist_hotttnesss', '<f8'), ('artist_id', 'S32'), ('artist_latitude', '<f8'), ('artist_location', 'S1024'), ('artist_longitude', '<f8'), ('artist_mbid', 'S40'), ('artist_name', 'S1024'), ('artist_playmeid', '<i4'), ('genre', 'S1024'), ('idx_artist_terms', '<i4'), ('idx_similar_artists', '<i4'), ('release', 'S1024'), ('release_7digitalid', '<i4'), ('song_hotttnesss', '<f8'), ('song_id', 'S32'), ('title', 'S1024'), ('track_7digitalid', '<i4')])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['metadata']['songs'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>metadata</th>\n",
       "      <th>musicbrainz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>artist_mbtags</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_mbtags_count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_terms</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[hip hop, underground rap, g funk, alternative...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_terms_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[1.0, 0.7761362332679642, 0.7296697949672141, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist_terms_weight</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[1.0, 0.8979359555142553, 0.8842618474718359, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bars_confidence</th>\n",
       "      <td>[0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0.4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bars_start</th>\n",
       "      <td>[0.58521, 2.94247, 5.14371, 7.74554, 10.36149,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beats_confidence</th>\n",
       "      <td>[0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.62...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beats_start</th>\n",
       "      <td>[0.58521, 1.19196, 1.78893, 2.37813, 2.94247, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sections_confidence</th>\n",
       "      <td>[1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sections_start</th>\n",
       "      <td>[0.0, 7.74554, 36.44331, 43.61667, 75.17954, 9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_confidence</th>\n",
       "      <td>[0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_loudness_max</th>\n",
       "      <td>[-60.0, -31.646, -34.565, -38.407, -34.696, -2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_loudness_max_time</th>\n",
       "      <td>[0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.073...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_loudness_start</th>\n",
       "      <td>[-60.0, -60.0, -40.84, -40.401, -38.456, -39.6...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_pitches</th>\n",
       "      <td>[[0.946, 0.684, 0.679, 0.941, 0.744, 0.633, 0....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_start</th>\n",
       "      <td>[0.0, 0.24671, 0.47116, 0.80376, 0.89551, 1.12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segments_timbre</th>\n",
       "      <td>[[0.0, 171.13, 9.469, -28.48, 57.491, -50.067,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar_artists</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[ARV4KO21187FB38008, ARWHM281187FB3D381, ARJGO...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>songs</th>\n",
       "      <td>[[22050, b'a222795e07cd65b7a530f1346f520649', ...</td>\n",
       "      <td>[[b'', 165270, 0.5817937658450281, 0.401997543...</td>\n",
       "      <td>[[0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tatums_confidence</th>\n",
       "      <td>[0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0.4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tatums_start</th>\n",
       "      <td>[0.28519, 0.58521, 0.89422, 1.19196, 1.49119, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     analysis  \\\n",
       "artist_mbtags                                                             NaN   \n",
       "artist_mbtags_count                                                       NaN   \n",
       "artist_terms                                                              NaN   \n",
       "artist_terms_freq                                                         NaN   \n",
       "artist_terms_weight                                                       NaN   \n",
       "bars_confidence             [0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0.4...   \n",
       "bars_start                  [0.58521, 2.94247, 5.14371, 7.74554, 10.36149,...   \n",
       "beats_confidence            [0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.62...   \n",
       "beats_start                 [0.58521, 1.19196, 1.78893, 2.37813, 2.94247, ...   \n",
       "sections_confidence         [1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373, ...   \n",
       "sections_start              [0.0, 7.74554, 36.44331, 43.61667, 75.17954, 9...   \n",
       "segments_confidence         [0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1.0...   \n",
       "segments_loudness_max       [-60.0, -31.646, -34.565, -38.407, -34.696, -2...   \n",
       "segments_loudness_max_time  [0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.073...   \n",
       "segments_loudness_start     [-60.0, -60.0, -40.84, -40.401, -38.456, -39.6...   \n",
       "segments_pitches            [[0.946, 0.684, 0.679, 0.941, 0.744, 0.633, 0....   \n",
       "segments_start              [0.0, 0.24671, 0.47116, 0.80376, 0.89551, 1.12...   \n",
       "segments_timbre             [[0.0, 171.13, 9.469, -28.48, 57.491, -50.067,...   \n",
       "similar_artists                                                           NaN   \n",
       "songs                       [[22050, b'a222795e07cd65b7a530f1346f520649', ...   \n",
       "tatums_confidence           [0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0.4...   \n",
       "tatums_start                [0.28519, 0.58521, 0.89422, 1.19196, 1.49119, ...   \n",
       "\n",
       "                                                                     metadata  \\\n",
       "artist_mbtags                                                             NaN   \n",
       "artist_mbtags_count                                                       NaN   \n",
       "artist_terms                [hip hop, underground rap, g funk, alternative...   \n",
       "artist_terms_freq           [1.0, 0.7761362332679642, 0.7296697949672141, ...   \n",
       "artist_terms_weight         [1.0, 0.8979359555142553, 0.8842618474718359, ...   \n",
       "bars_confidence                                                           NaN   \n",
       "bars_start                                                                NaN   \n",
       "beats_confidence                                                          NaN   \n",
       "beats_start                                                               NaN   \n",
       "sections_confidence                                                       NaN   \n",
       "sections_start                                                            NaN   \n",
       "segments_confidence                                                       NaN   \n",
       "segments_loudness_max                                                     NaN   \n",
       "segments_loudness_max_time                                                NaN   \n",
       "segments_loudness_start                                                   NaN   \n",
       "segments_pitches                                                          NaN   \n",
       "segments_start                                                            NaN   \n",
       "segments_timbre                                                           NaN   \n",
       "similar_artists             [ARV4KO21187FB38008, ARWHM281187FB3D381, ARJGO...   \n",
       "songs                       [[b'', 165270, 0.5817937658450281, 0.401997543...   \n",
       "tatums_confidence                                                         NaN   \n",
       "tatums_start                                                              NaN   \n",
       "\n",
       "                           musicbrainz  \n",
       "artist_mbtags                       []  \n",
       "artist_mbtags_count                 []  \n",
       "artist_terms                       NaN  \n",
       "artist_terms_freq                  NaN  \n",
       "artist_terms_weight                NaN  \n",
       "bars_confidence                    NaN  \n",
       "bars_start                         NaN  \n",
       "beats_confidence                   NaN  \n",
       "beats_start                        NaN  \n",
       "sections_confidence                NaN  \n",
       "sections_start                     NaN  \n",
       "segments_confidence                NaN  \n",
       "segments_loudness_max              NaN  \n",
       "segments_loudness_max_time         NaN  \n",
       "segments_loudness_start            NaN  \n",
       "segments_pitches                   NaN  \n",
       "segments_start                     NaN  \n",
       "segments_timbre                    NaN  \n",
       "similar_artists                    NaN  \n",
       "songs                         [[0, 0]]  \n",
       "tatums_confidence                  NaN  \n",
       "tatums_start                       NaN  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index_dict = {}\n",
    "for i, key in enumerate (d.keys()):\n",
    "    for j, key2 in enumerate(d[key].keys()):\n",
    "        multi_index_dict[(key,key2)] = [d[key][key2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_1 = pd.DataFrame(multi_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e96fbc2e4b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msong_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msong_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "db = pd.concat([song_1,song_1])\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(analysis, bars_confidence)</th>\n",
       "      <th>(analysis, bars_start)</th>\n",
       "      <th>(analysis, beats_confidence)</th>\n",
       "      <th>(analysis, beats_start)</th>\n",
       "      <th>(analysis, sections_confidence)</th>\n",
       "      <th>(analysis, sections_start)</th>\n",
       "      <th>(analysis, segments_confidence)</th>\n",
       "      <th>(analysis, segments_loudness_max)</th>\n",
       "      <th>(analysis, segments_loudness_max_time)</th>\n",
       "      <th>(analysis, segments_loudness_start)</th>\n",
       "      <th>...</th>\n",
       "      <th>(analysis, tatums_confidence)</th>\n",
       "      <th>(analysis, tatums_start)</th>\n",
       "      <th>(metadata, artist_terms)</th>\n",
       "      <th>(metadata, artist_terms_freq)</th>\n",
       "      <th>(metadata, artist_terms_weight)</th>\n",
       "      <th>(metadata, similar_artists)</th>\n",
       "      <th>(metadata, songs)</th>\n",
       "      <th>(musicbrainz, artist_mbtags)</th>\n",
       "      <th>(musicbrainz, artist_mbtags_count)</th>\n",
       "      <th>(musicbrainz, songs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0....</td>\n",
       "      <td>[[0.58521, 2.94247, 5.14371, 7.74554, 10.36149...</td>\n",
       "      <td>[[0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.6...</td>\n",
       "      <td>[[0.58521, 1.19196, 1.78893, 2.37813, 2.94247,...</td>\n",
       "      <td>[[1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373,...</td>\n",
       "      <td>[[0.0, 7.74554, 36.44331, 43.61667, 75.17954, ...</td>\n",
       "      <td>[[0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1....</td>\n",
       "      <td>[[-60.0, -31.646, -34.565, -38.407, -34.696, -...</td>\n",
       "      <td>[[0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.07...</td>\n",
       "      <td>[[-60.0, -60.0, -40.84, -40.401, -38.456, -39....</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0....</td>\n",
       "      <td>[[0.28519, 0.58521, 0.89422, 1.19196, 1.49119,...</td>\n",
       "      <td>[[hip hop, underground rap, g funk, alternativ...</td>\n",
       "      <td>[[1.0, 0.7761362332679642, 0.7296697949672141,...</td>\n",
       "      <td>[[1.0, 0.8979359555142553, 0.8842618474718359,...</td>\n",
       "      <td>[[ARV4KO21187FB38008, ARWHM281187FB3D381, ARJG...</td>\n",
       "      <td>[[[b'', 165270, 0.5817937658450281, 0.40199754...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0, 0]]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0....</td>\n",
       "      <td>[[0.58521, 2.94247, 5.14371, 7.74554, 10.36149...</td>\n",
       "      <td>[[0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.6...</td>\n",
       "      <td>[[0.58521, 1.19196, 1.78893, 2.37813, 2.94247,...</td>\n",
       "      <td>[[1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373,...</td>\n",
       "      <td>[[0.0, 7.74554, 36.44331, 43.61667, 75.17954, ...</td>\n",
       "      <td>[[0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1....</td>\n",
       "      <td>[[-60.0, -31.646, -34.565, -38.407, -34.696, -...</td>\n",
       "      <td>[[0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.07...</td>\n",
       "      <td>[[-60.0, -60.0, -40.84, -40.401, -38.456, -39....</td>\n",
       "      <td>...</td>\n",
       "      <td>[[0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0....</td>\n",
       "      <td>[[0.28519, 0.58521, 0.89422, 1.19196, 1.49119,...</td>\n",
       "      <td>[[hip hop, underground rap, g funk, alternativ...</td>\n",
       "      <td>[[1.0, 0.7761362332679642, 0.7296697949672141,...</td>\n",
       "      <td>[[1.0, 0.8979359555142553, 0.8842618474718359,...</td>\n",
       "      <td>[[ARV4KO21187FB38008, ARWHM281187FB3D381, ARJG...</td>\n",
       "      <td>[[[b'', 165270, 0.5817937658450281, 0.40199754...</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[[0, 0]]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         (analysis, bars_confidence)  \\\n",
       "0  [[0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0....   \n",
       "1  [[0.643, 0.746, 0.722, 0.095, 0.091, 0.362, 0....   \n",
       "\n",
       "                              (analysis, bars_start)  \\\n",
       "0  [[0.58521, 2.94247, 5.14371, 7.74554, 10.36149...   \n",
       "1  [[0.58521, 2.94247, 5.14371, 7.74554, 10.36149...   \n",
       "\n",
       "                        (analysis, beats_confidence)  \\\n",
       "0  [[0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.6...   \n",
       "1  [[0.834, 0.851, 0.65, 0.635, 0.532, 0.753, 0.6...   \n",
       "\n",
       "                             (analysis, beats_start)  \\\n",
       "0  [[0.58521, 1.19196, 1.78893, 2.37813, 2.94247,...   \n",
       "1  [[0.58521, 1.19196, 1.78893, 2.37813, 2.94247,...   \n",
       "\n",
       "                     (analysis, sections_confidence)  \\\n",
       "0  [[1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373,...   \n",
       "1  [[1.0, 1.0, 0.218, 0.133, 0.384, 0.326, 0.373,...   \n",
       "\n",
       "                          (analysis, sections_start)  \\\n",
       "0  [[0.0, 7.74554, 36.44331, 43.61667, 75.17954, ...   \n",
       "1  [[0.0, 7.74554, 36.44331, 43.61667, 75.17954, ...   \n",
       "\n",
       "                     (analysis, segments_confidence)  \\\n",
       "0  [[0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1....   \n",
       "1  [[0.0, 1.0, 0.483, 0.137, 0.42, 1.0, 0.257, 1....   \n",
       "\n",
       "                   (analysis, segments_loudness_max)  \\\n",
       "0  [[-60.0, -31.646, -34.565, -38.407, -34.696, -...   \n",
       "1  [[-60.0, -31.646, -34.565, -38.407, -34.696, -...   \n",
       "\n",
       "              (analysis, segments_loudness_max_time)  \\\n",
       "0  [[0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.07...   \n",
       "1  [[0.0, 0.10929, 0.11044, 0.0844, 0.05898, 0.07...   \n",
       "\n",
       "                 (analysis, segments_loudness_start)  ...  \\\n",
       "0  [[-60.0, -60.0, -40.84, -40.401, -38.456, -39....  ...   \n",
       "1  [[-60.0, -60.0, -40.84, -40.401, -38.456, -39....  ...   \n",
       "\n",
       "                       (analysis, tatums_confidence)  \\\n",
       "0  [[0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0....   \n",
       "1  [[0.779, 0.734, 0.674, 0.637, 0.597, 0.532, 0....   \n",
       "\n",
       "                            (analysis, tatums_start)  \\\n",
       "0  [[0.28519, 0.58521, 0.89422, 1.19196, 1.49119,...   \n",
       "1  [[0.28519, 0.58521, 0.89422, 1.19196, 1.49119,...   \n",
       "\n",
       "                            (metadata, artist_terms)  \\\n",
       "0  [[hip hop, underground rap, g funk, alternativ...   \n",
       "1  [[hip hop, underground rap, g funk, alternativ...   \n",
       "\n",
       "                       (metadata, artist_terms_freq)  \\\n",
       "0  [[1.0, 0.7761362332679642, 0.7296697949672141,...   \n",
       "1  [[1.0, 0.7761362332679642, 0.7296697949672141,...   \n",
       "\n",
       "                     (metadata, artist_terms_weight)  \\\n",
       "0  [[1.0, 0.8979359555142553, 0.8842618474718359,...   \n",
       "1  [[1.0, 0.8979359555142553, 0.8842618474718359,...   \n",
       "\n",
       "                         (metadata, similar_artists)  \\\n",
       "0  [[ARV4KO21187FB38008, ARWHM281187FB3D381, ARJG...   \n",
       "1  [[ARV4KO21187FB38008, ARWHM281187FB3D381, ARJG...   \n",
       "\n",
       "                                   (metadata, songs)  \\\n",
       "0  [[[b'', 165270, 0.5817937658450281, 0.40199754...   \n",
       "1  [[[b'', 165270, 0.5817937658450281, 0.40199754...   \n",
       "\n",
       "  (musicbrainz, artist_mbtags) (musicbrainz, artist_mbtags_count)  \\\n",
       "0                         [[]]                               [[]]   \n",
       "1                         [[]]                               [[]]   \n",
       "\n",
       "  (musicbrainz, songs)  \n",
       "0           [[[0, 0]]]  \n",
       "1           [[[0, 0]]]  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([multi_index_dict,multi_index_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-242-9a8d2730db60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({('A','a'):[1,2,3],('B','b'):[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n",
      "b'a222795e07cd65b7a530f1346f520649'\n",
      "a222795e07cd65b7a530f1346f520649\n",
      "0.0\n",
      "218.93179\n",
      "0.247\n",
      "0.0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0.736\n",
      "-11.197\n",
      "0\n",
      "0.636\n",
      "218.932\n",
      "92.198\n",
      "4\n",
      "0.778\n",
      "b'TRAAAAW128F429D538'\n",
      "TRAAAAW128F429D538\n"
     ]
    }
   ],
   "source": [
    "for i, entry in enumerate(d['analysis']['songs'][0]):\n",
    "    print (entry)\n",
    "    if type(entry) == np.bytes_:\n",
    "        print(entry.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22050, b'a222795e07cd65b7a530f1346f520649', 0., 218.93179, 0.247, 0., 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.736, -11.197, 0, 0.636, 218.932, 92.198, 4, 0.778, b'TRAAAAW128F429D538')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['analysis']['songs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = pd.HDFStore('data/A/A/A/TRAAAAW128F429D538.h5', mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: data/A/A/A/TRAAAAW128F429D538.h5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song.open()\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bars_confidence',\n",
       " 'bars_start',\n",
       " 'beats_confidence',\n",
       " 'beats_start',\n",
       " 'sections_confidence',\n",
       " 'sections_start',\n",
       " 'segments_confidence',\n",
       " 'segments_loudness_max',\n",
       " 'segments_loudness_max_time',\n",
       " 'segments_loudness_start',\n",
       " 'segments_pitches',\n",
       " 'segments_start',\n",
       " 'segments_timbre',\n",
       " 'songs',\n",
       " 'tatums_confidence',\n",
       " 'tatums_start']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['analysis', 'metadata', 'musicbrainz']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f['musicbrainz']['songs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No dataset in HDF5 file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e251bb97e61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/A/A/A/TRAAAAW128F429D538.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, key = a_group_key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No dataset in HDF5 file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0mcandidate_only_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No dataset in HDF5 file."
     ]
    }
   ],
   "source": [
    "pd.read_hdf('data/A/A/A/TRAAAAW128F429D538.h5')#, key = a_group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tutorial for the Million Song Dataset\n",
    "\n",
    "by Thierry Bertin-Mahieux (2011) Columbia University\n",
    "   tb2332@columbia.edu\n",
    "   Copyright 2011 T. Bertin-Mahieux, All Rights Reserved\n",
    "\n",
    "This tutorial will walk you through a quick experiment\n",
    "using the Million Song Dataset (MSD). We will actually be working\n",
    "on the 10K songs subset for speed issues, but the code should\n",
    "transpose seamlessly.\n",
    "\n",
    "In this tutorial, we do simple metadata analysis. We look at\n",
    "which artist has the most songs by iterating over the whole\n",
    "dataset and using an SQLite database.\n",
    "\n",
    "You need to have the MSD code downloaded from GITHUB.\n",
    "See the MSD website for details:\n",
    "http://labrosa.ee.columbia.edu/millionsong/\n",
    "\n",
    "If you have any questions regarding the dataset or this tutorial,\n",
    "please first take a look at the website. Send us an email\n",
    "if you haven't found the answer.\n",
    "\n",
    "Note: this tutorial is developed using Python 2.6\n",
    "      on an Ubuntu machine. PDF created using 'pyreport'.\n",
    "\"\"\"\n",
    "\n",
    "# usual imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import sqlite3\n",
    "import numpy as np # get it at: http://numpy.scipy.org/\n",
    "# path to the Million Song Dataset subset (uncompressed)\n",
    "# CHANGE IT TO YOUR LOCAL CONFIGURATION\n",
    "msd_subset_path='/Users/Maxwell/galvanize/capstone/million-song-subset/MillionSongSubset/'\n",
    "msd_subset_data_path=os.path.join(msd_subset_path,'data')\n",
    "msd_subset_addf_path=os.path.join(msd_subset_path,'AdditionalFiles')\n",
    "assert os.path.isdir(msd_subset_path),'wrong path' # sanity check\n",
    "# path to the Million Song Dataset code\n",
    "# CHANGE IT TO YOUR LOCAL CONFIGURATION\n",
    "msd_code_path='/Users/Maxwell/galvanize/capstone/million-song-subset/MillionSongSubset/'\n",
    "assert os.path.isdir(msd_code_path),'wrong path' # sanity check\n",
    "# we add some paths to python so we can import MSD code\n",
    "# Ubuntu: you can change the environment variable PYTHONPATH\n",
    "# in your .bashrc file so you do not have to type these lines\n",
    "sys.path.append( os.path.join(msd_code_path,'PythonSrc') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of song files: 10000\n"
     ]
    }
   ],
   "source": [
    "# imports specific to the MSD\n",
    "# import hdf5_getters as GETTERS\n",
    "\n",
    "# the following function simply gives us a nice string for\n",
    "# a time lag in seconds\n",
    "def strtimedelta(starttime,stoptime):\n",
    "    return str(datetime.timedelta(seconds=stoptime-starttime))\n",
    "\n",
    "# we define this very useful function to iterate the files\n",
    "def apply_to_all_files(basedir,func=lambda x: x,ext='.h5'):\n",
    "    \"\"\"\n",
    "    From a base directory, go through all subdirectories,\n",
    "    find all files with the given extension, apply the\n",
    "    given function 'func' to all of them.\n",
    "    If no 'func' is passed, we do nothing except counting.\n",
    "    INPUT\n",
    "       basedir  - base directory of the dataset\n",
    "       func     - function to apply to all filenames\n",
    "       ext      - extension, .h5 by default\n",
    "    RETURN\n",
    "       number of files\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    # iterate over all files in all subdirectories\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        # count files\n",
    "        cnt += len(files)\n",
    "        # apply function to all files\n",
    "        for f in files :\n",
    "            func(f)       \n",
    "    return cnt\n",
    "\n",
    "# we can now easily count the number of files in the dataset\n",
    "print ('number of song files:',apply_to_all_files(msd_subset_data_path))\n",
    "\n",
    "# let's now get all artist names in a set(). One nice property:\n",
    "# if we enter many times the same artist, only one will be kept.\n",
    "all_artist_names = set()\n",
    "\n",
    "# we define the function to apply to all files\n",
    "def func_to_get_artist_name(filename):\n",
    "    \"\"\"\n",
    "    This function does 3 simple things:\n",
    "    - open the song file\n",
    "    - get artist ID and put it\n",
    "    - close the file\n",
    "    \"\"\"\n",
    "#     f = h5py.File(filename, 'r')\n",
    "    h5 = GETTERS.open_h5_file_read(filename)\n",
    "    artist_name = GETTERS.get_artist_name(h5)\n",
    "    all_artist_names.add( artist_name )\n",
    "    h5.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-7c6d1fc22787>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7c6d1fc22787>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    h5py.h5.\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "h5py.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GETTERS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-376dae66c3a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# we'll also measure how long it takes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mapply_to_all_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsd_subset_data_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_to_get_artist_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'all artist names extracted in:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1d461151295d>\u001b[0m in \u001b[0;36mapply_to_all_files\u001b[0;34m(basedir, func, ext)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# apply function to all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1d461151295d>\u001b[0m in \u001b[0;36mfunc_to_get_artist_name\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#     f = h5py.File(filename, 'r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGETTERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_h5_file_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0martist_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGETTERS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_artist_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mall_artist_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0martist_name\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GETTERS' is not defined"
     ]
    }
   ],
   "source": [
    "   \n",
    "# let's apply the previous function to all files\n",
    "# we'll also measure how long it takes\n",
    "t1 = time.time()\n",
    "apply_to_all_files(msd_subset_data_path,func=func_to_get_artist_name)\n",
    "t2 = time.time()\n",
    "print ('all artist names extracted in:',strtimedelta(t1,t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-ad69bcc83a87>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-ad69bcc83a87>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print 'found',len(all_artist_names),'unique artist names'\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# let's see some of the content of 'all_artist_names'\n",
    "print 'found',len(all_artist_names),'unique artist names'\n",
    "for k in range(5):\n",
    "    print list(all_artist_names)[k]\n",
    "\n",
    "# this is too long, and the work of listing artist names has already\n",
    "# been done. Let's redo the same task using an SQLite database.\n",
    "# We connect to the provided database: track_metadata.db\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "# we build the SQL query\n",
    "q = \"SELECT DISTINCT artist_name FROM songs\"\n",
    "# we query the database\n",
    "t1 = time.time()\n",
    "res = conn.execute(q)\n",
    "all_artist_names_sqlite = res.fetchall()\n",
    "t2 = time.time()\n",
    "print 'all artist names extracted (SQLite) in:',strtimedelta(t1,t2)\n",
    "# we close the connection to the database\n",
    "conn.close()\n",
    "# let's see some of the content\n",
    "for k in range(5):\n",
    "    print all_artist_names_sqlite[k][0]\n",
    "\n",
    "# now, let's find the artist that has the most songs in the dataset\n",
    "# what we want to work with is artist ID, not artist names. Some artists\n",
    "# have many names, usually because the song is \"featuring someone else\"\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "q = \"SELECT DISTINCT artist_id FROM songs\"\n",
    "res = conn.execute(q)\n",
    "all_artist_ids = map(lambda x: x[0], res.fetchall())\n",
    "conn.close()\n",
    "\n",
    "# The Echo Nest artist id look like:\n",
    "for k in range(4):\n",
    "    print all_artist_ids[k]\n",
    "\n",
    "# let's count the songs from each of these artists.\n",
    "# We will do it first by iterating over the dataset.\n",
    "# we prepare a dictionary to count files\n",
    "files_per_artist = {}\n",
    "for aid in all_artist_ids:\n",
    "    files_per_artist[aid] = 0\n",
    "\n",
    "# we prepare the function to check artist id in each file\n",
    "def func_to_count_artist_id(filename):\n",
    "    \"\"\"\n",
    "    This function does 3 simple things:\n",
    "    - open the song file\n",
    "    - get artist ID and put it\n",
    "    - close the file\n",
    "    \"\"\"\n",
    "    h5 = GETTERS.open_h5_file_read(filename)\n",
    "    artist_id = GETTERS.get_artist_id(h5)\n",
    "    files_per_artist[artist_id] += 1\n",
    "    h5.close()\n",
    "\n",
    "# we apply this function to all files\n",
    "apply_to_all_files(msd_subset_data_path,func=func_to_count_artist_id)\n",
    "\n",
    "# the most popular artist (with the most songs) is:\n",
    "most_pop_aid = sorted(files_per_artist,\n",
    "                      key=files_per_artist.__getitem__,\n",
    "                      reverse=True)[0]\n",
    "print most_pop_aid,'has',files_per_artist[most_pop_aid],'songs.'\n",
    "\n",
    "# of course, it is more fun to have the name(s) of this artist\n",
    "# let's get it using SQLite\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "q = \"SELECT DISTINCT artist_name FROM songs\"\n",
    "q += \" WHERE artist_id='\"+most_pop_aid+\"'\"\n",
    "res = conn.execute(q)\n",
    "pop_artist_names = map(lambda x: x[0], res.fetchall())\n",
    "conn.close()\n",
    "print 'SQL query:',q\n",
    "print 'name(s) of the most popular artist:',pop_artist_names\n",
    "\n",
    "# let's redo all this work in SQLite in a few seconds\n",
    "t1 = time.time()\n",
    "conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                    'subset_track_metadata.db'))\n",
    "q = \"SELECT DISTINCT artist_id,artist_name,Count(track_id) FROM songs\"\n",
    "q += \" GROUP BY artist_id\"\n",
    "res = conn.execute(q)\n",
    "pop_artists = res.fetchall()\n",
    "conn.close()\n",
    "t2 = time.time()\n",
    "print 'found most popular artist in',strtimedelta(t1,t2)\n",
    "print sorted(pop_artists,key=lambda x:x[2],reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting Integration with 7Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hdf5_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4b22b3257943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mpythonsrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpythonsrc\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpythonsrc\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_getters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGETTERS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hdf5_utils'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Thierry Bertin-Mahieux (2010) Columbia University\n",
    "tb2332@columbia.edu\n",
    "\n",
    "\n",
    "This code uses 7digital API and info contained in HDF5 song\n",
    "file to get a preview URL.\n",
    "\n",
    "This is part of the Million Song Dataset project from\n",
    "LabROSA (Columbia University) and The Echo Nest.\n",
    "\n",
    "\n",
    "Copyright 2010, Thierry Bertin-Mahieux\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# import urllib2\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "try:\n",
    "    from numpy import argmin\n",
    "except ImportError:\n",
    "    from scipy import argmin\n",
    "except ImportError:\n",
    "    print ('no argmin function (no numpy or scipy), might cause problems')\n",
    "from xml.dom import minidom\n",
    "\n",
    "# Million Song Dataset imports, works under Linux\n",
    "# otherwise, put the PythonSrc directory in the PYTHONPATH!\n",
    "pythonsrc = os.path.abspath('__file__')\n",
    "pythonsrc = os.path.join(pythonsrc,'../../../PythonSrc')\n",
    "pythonsrc = os.path.abspath( pythonsrc )\n",
    "sys.path.append( pythonsrc )\n",
    "import hdf5_utils\n",
    "import hdf5_getters as GETTERS\n",
    "\n",
    "# try to get 7digital API key\n",
    "global DIGITAL7_API_KEY\n",
    "try:\n",
    "    DIGITAL7_API_KEY = os.environ['DIGITAL7_API_KEY']\n",
    "except KeyError:\n",
    "    DIGITAL7_API_KEY = None\n",
    "\n",
    "\n",
    "\n",
    "def url_call(url):\n",
    "    \"\"\"\n",
    "    Do a simple request to the 7digital API\n",
    "    We assume we don't do intense querying, this function is not\n",
    "    robust\n",
    "    Return the answer as na xml document\n",
    "    \"\"\"\n",
    "    stream = urlopen(url)\n",
    "    xmldoc = minidom.parse(stream).documentElement\n",
    "    stream.close()\n",
    "    return xmldoc\n",
    "\n",
    "\n",
    "def levenshtein(s1, s2):\n",
    "    \"\"\"\n",
    "    Levenstein distance, or edit distance, taken from Wikibooks:\n",
    "    http://en.wikibooks.org/wiki/Algorithm_implementation/Strings/Levenshtein_distance#Python\n",
    "    \"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    if not s1:\n",
    "        return len(s2)\n",
    " \n",
    "    previous_row = xrange(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    " \n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def get_closest_track(tracklist,target):\n",
    "    \"\"\"\n",
    "    Find the closest track based on edit distance\n",
    "    Might not be an exact match, you should check!\n",
    "    \"\"\"\n",
    "    dists = map(lambda x: levenshtein(x,target),tracklist)\n",
    "    best = argmin(dists)\n",
    "    return tracklist[best]\n",
    "\n",
    "\n",
    "def get_trackid_from_text_search(title,artistname=''):\n",
    "    \"\"\"\n",
    "    Search for an artist + title using 7digital search API\n",
    "    Return None if there is a problem, or tuple (title,trackid)\n",
    "    \"\"\"\n",
    "    url = 'http://api.7digital.com/1.2/track/search?'\n",
    "    url += 'oauth_consumer_key='+DIGITAL7_API_KEY\n",
    "    query = title\n",
    "    if artistname != '':\n",
    "        query = artistname + ' ' + query\n",
    "    query = urllib.parse.quote(query)\n",
    "    url += '&q='+query\n",
    "    xmldoc = url_call(url)\n",
    "    status = xmldoc.getAttribute('status')\n",
    "    if status != 'ok':\n",
    "        return None\n",
    "    resultelem = xmldoc.getElementsByTagName('searchResult')\n",
    "    if len(resultelem) == 0:\n",
    "        return None\n",
    "    track = resultelem[0].getElementsByTagName('track')[0]\n",
    "    tracktitle = track.getElementsByTagName('title')[0].firstChild.data\n",
    "    trackid = int(track.getAttribute('id'))\n",
    "    return (tracktitle,trackid)\n",
    "\n",
    "    \n",
    "def get_tracks_from_artistid(artistid):\n",
    "    \"\"\"\n",
    "    We get a list of release from artists.\n",
    "    For each of these, get release.\n",
    "    After calling the API with a given release ID, we receive a list of tracks.\n",
    "    We return a map of <track name> -> <track id>\n",
    "    or None if there is a problem\n",
    "    \"\"\"\n",
    "    url = 'http://api.7digital.com/1.2/artist/releases?'\n",
    "    url += '&artistid='+str(artistid)\n",
    "    url += '&oauth_consumer_key='+DIGITAL7_API_KEY\n",
    "    xmldoc = url_call(url)\n",
    "    status = xmldoc.getAttribute('status')\n",
    "    if status != 'ok':\n",
    "        return None\n",
    "    releaseselem = xmldoc.getElementsByTagName('releases')[0]\n",
    "    releases = releaseselem.getElementsByTagName('release')\n",
    "    if len(releases) == 0:\n",
    "        return None\n",
    "    releases_ids = map(lambda x: int(x.getAttribute('id')), releases)\n",
    "    res = {}\n",
    "    for rid in releases_ids:\n",
    "        tmpres = get_tracks_from_releaseid(rid)\n",
    "        if tmpres is not None:\n",
    "            res.update(tmpres)\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_tracks_from_releaseid(releaseid):\n",
    "    \"\"\"\n",
    "    After calling the API with a given release ID, we receive a list of tracks.\n",
    "    We return a map of <track name> -> <track id>\n",
    "    or None if there is a problem\n",
    "    \"\"\"\n",
    "    url = 'http://api.7digital.com/1.2/release/tracks?'\n",
    "    url += 'releaseid='+str(releaseid)\n",
    "    url += '&oauth_consumer_key='+DIGITAL7_API_KEY\n",
    "    xmldoc = url_call(url)\n",
    "    status = xmldoc.getAttribute('status')\n",
    "    if status != 'ok':\n",
    "        return None\n",
    "    tracks = xmldoc.getElementsByTagName('track')\n",
    "    if len(tracks)==0:\n",
    "        return None\n",
    "    res = {}\n",
    "    for t in tracks:\n",
    "        tracktitle = t.getElementsByTagName('title')[0].firstChild.data\n",
    "        trackid = int(t.getAttribute('id'))\n",
    "        res[tracktitle] = trackid\n",
    "    return res\n",
    "    \n",
    "\n",
    "def get_preview_from_trackid(trackid):\n",
    "    \"\"\"\n",
    "    Ask for the preview to a particular track, get the XML answer\n",
    "    After calling the API with a given track id,\n",
    "    we get an XML response that looks like:\n",
    "    \n",
    "    <response status=\"ok\" version=\"1.2\" xsi:noNamespaceSchemaLocation=\"http://api.7digital.com/1.2/static/7digitalAPI.xsd\">\n",
    "      <url>\n",
    "        http://previews.7digital.com/clips/34/6804688.clip.mp3\n",
    "      </url>\n",
    "    </response>\n",
    "\n",
    "    We parse it for the URL that we return, or '' if a problem\n",
    "    \"\"\"\n",
    "    url = 'http://api.7digital.com/1.2/track/preview?redirect=false'\n",
    "    url += '&trackid='+str(trackid)\n",
    "    url += '&oauth_consumer_key='+DIGITAL7_API_KEY\n",
    "    xmldoc = url_call(url)\n",
    "    status = xmldoc.getAttribute('status')\n",
    "    if status != 'ok':\n",
    "        return ''\n",
    "    urlelem = xmldoc.getElementsByTagName('url')[0]\n",
    "    preview = urlelem.firstChild.nodeValue\n",
    "    return preview\n",
    "\n",
    "\n",
    "def die_with_usage():\n",
    "    \"\"\" HELP MENU \"\"\"\n",
    "    print ('get_preview_url.py')\n",
    "    print ('    by T. Bertin-Mahieux (2010) Columbia University')\n",
    "    print ('HELP MENU')\n",
    "    print ('usage:')\n",
    "    print ('    python get_preview_url.py [FLAG] <SONGFILE>')\n",
    "    print ('PARAMS:')\n",
    "    print ('  <SONGFILE>  - a Million Song Dataset file TRABC...123.h5')\n",
    "    print ('FLAGS:')\n",
    "    print ('  -7digitalkey KEY - API key from 7 digital, we recomment you put it')\n",
    "    print ('                     under environment variable: DIGITAL7_API_KEY')\n",
    "    print ('OUTPUT:')\n",
    "    print ('  url from 7digital that should play a clip of the song.')\n",
    "    print ('  No guarantee that this is the exact audio used for the analysis')\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # help menu\n",
    "    if len(sys.argv) < 2:\n",
    "        die_with_usage()\n",
    "\n",
    "    # flags\n",
    "    while True:\n",
    "        if sys.argv[1] == '-7digitalkey':\n",
    "            DIGITAL7_API_KEY = sys.argv[2]\n",
    "            sys.argv.pop(1)\n",
    "        else:\n",
    "            break\n",
    "        sys.argv.pop(1)\n",
    "\n",
    "    # params\n",
    "    h5path = sys.argv[1]\n",
    "\n",
    "    # sanity checks\n",
    "    if DIGITAL7_API_KEY is None:\n",
    "        print ('You need to set a 7digital API key!')\n",
    "        print ('Get one at: http://developer.7digital.net/')\n",
    "        print ('Pass it as a flag: -7digitalkey KEY')\n",
    "        print ('or set it under environment variable: DIGITAL7_API_KEY')\n",
    "        sys.exit(0)\n",
    "    if not os.path.isfile(h5path):\n",
    "        print ('invalid path (not a file):',h5path)\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "    # open h5 song, get all we know about the song\n",
    "    h5 = hdf5_utils.open_h5_file_read(h5path)\n",
    "    track_7digitalid = GETTERS.get_track_7digitalid(h5)\n",
    "    release_7digitalid = GETTERS.get_release_7digitalid(h5)\n",
    "    artist_7digitalid = GETTERS.get_artist_7digitalid(h5)\n",
    "    artist_name = GETTERS.get_artist_name(h5)\n",
    "    release_name = GETTERS.get_release(h5)\n",
    "    track_name = GETTERS.get_title(h5)\n",
    "    h5.close()\n",
    "\n",
    "    # we already have the 7digital track id? way too easy!\n",
    "    if track_7digitalid >= 0:\n",
    "        preview = get_preview_from_trackid(track_7digitalid)\n",
    "        if preview == '':\n",
    "            print ('something went wrong when looking by track id')\n",
    "        else:\n",
    "            print (preview)\n",
    "            sys.exit(0)\n",
    "\n",
    "    # we have the release id? get all tracks, find the closest match\n",
    "    if release_7digitalid >= 0:\n",
    "        tracks_name_ids = get_tracks_from_releaseid(release_7digitalid)\n",
    "        if tracks_name_ids is None:\n",
    "            print ('something went wrong when looking by album id')\n",
    "        else:\n",
    "            closest_track = get_closest_track(tracks_name_ids.keys(),track_name)\n",
    "            if closest_track != track_name:\n",
    "                print ('we approximate your song title:',track_name,'by:',closest_track)\n",
    "            preview = get_preview_from_trackid(tracks_name_ids[closest_track])\n",
    "            if preview == '':\n",
    "                print ('something went wrong when looking by track id after release id')\n",
    "            else:\n",
    "                print (preview)\n",
    "                sys.exit(0)\n",
    "            \n",
    "    # we have the artist id? get all albums, get all tracks, find the closest match\n",
    "    if artist_7digitalid >= 0:\n",
    "        tracks_name_ids = get_tracks_from_artistid(artist_7digitalid)\n",
    "        if tracks_name_ids is None:\n",
    "            print ('something went wrong when looking by artist id')\n",
    "        else:\n",
    "            closest_track = get_closest_track(tracks_name_ids.keys(),track_name)\n",
    "            if closest_track != track_name:\n",
    "                print ('we approximate your song title:',track_name,'by:',closest_track)\n",
    "            preview = get_preview_from_trackid(tracks_name_ids[closest_track])\n",
    "            if preview == '':\n",
    "                print ('something went wrong when looking by track id after artist id')\n",
    "            else:\n",
    "                print (preview)\n",
    "                sys.exit(0)\n",
    "\n",
    "    # damn it! search by artist name + track title\n",
    "    else:\n",
    "        res = get_trackid_from_text_search(track_name,artistname=artist_name)\n",
    "        if res is None:\n",
    "            print ('something went wrong when doing text search with artist and track name, no more ideas')\n",
    "            sys.exit(0)\n",
    "        closest_track,trackid = res\n",
    "        if closest_track != track_name:\n",
    "            print ('we approximate your song title:',track_name,'by:',closest_track)\n",
    "        preview = get_preview_from_trackid(trackid)\n",
    "        if preview == '':\n",
    "            print ('something went wrong when looking by track id after text searching by artist and track name')\n",
    "        else:\n",
    "            print (preview)\n",
    "            sys.exit(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
