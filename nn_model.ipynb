{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Neural Network to Predict Record Producer from Featurized Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Spotify's Audio Analysis contains a feature called `timbre` which contains information about the qualities of sound that are not found in pitch. From Spotify\n",
    "\n",
    ">*Timbre is the quality of a musical note or sound that distinguishes different types of musical instruments, or voices. It is a complex notion also referred to as sound color, texture, or tone quality, and is derived from the shape of a segmentâ€™s spectro-temporal surface, independently of pitch and loudness. The timbre feature is a vector that includes 12 unbounded values roughly centered around 0. Those values are high level abstractions of the spectral surface, ordered by degree of importance.*\n",
    "\n",
    "I believe that a producer's ***Signature Sound*** can be found in these timbre vectors.\n",
    "\n",
    "I will use `TensorFlow.keras` to create a Convolutional Neural Network that will categorically predict record producer from audio snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Builds the neural network model\n",
    "\"\"\"\n",
    "\n",
    "# Standard Imports\n",
    "from matplotlib.pyplot import imread, imshow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.constraints import min_max_norm, non_neg\n",
    "# import kernels\n",
    "# from artist import CustomImage, ImageBundle\n",
    "import pickle\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MongoDB\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "# Access/Initiate Database\n",
    "db = client['producer_db']\n",
    "# Access/Initiate Table\n",
    "tab = db['songs']\n",
    "collection = db.tab\n",
    "\n",
    "# Authorize Spotify API\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_id = os.environ['SPOTIFY_CLIENT_ID']\n",
    "client_secret = os.environ['SPOTIFY_CLIENT_SECRET']\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(32, activation='relu'))\n",
    "# model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (9, 3), (3, 9), (3, 3, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "\n",
    "b = np.concatenate([a,a,a], axis = 0)\n",
    "c = np.concatenate([a,a,a], axis = 1)\n",
    "d = np.stack([a,a,a], axis = 2)\n",
    "\n",
    "a.shape, b.shape, c.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = collection.find({'producer':'George Martin'})\n",
    "rr = collection.find({'producer':'Rick Rubin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George Martin',\n",
       " 'Dr. Dre',\n",
       " 'Rick Rubin',\n",
       " 'Brian Eno',\n",
       " 'Stock Aitken Waterman',\n",
       " 'Paul Epworth',\n",
       " 'Pete Rock']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.distinct('producer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Rick Rubin', 'count': 2039},\n",
      " {'_id': 'Dr. Dre', 'count': 1498},\n",
      " {'_id': 'George Martin', 'count': 1420},\n",
      " {'_id': 'Pete Rock', 'count': 1034},\n",
      " {'_id': 'Brian Eno', 'count': 924},\n",
      " {'_id': 'Paul Epworth', 'count': 478},\n",
      " {'_id': 'Stock Aitken Waterman', 'count': 436}]\n"
     ]
    }
   ],
   "source": [
    "from bson.son import SON\n",
    "pipeline = [\n",
    "    {\"$unwind\": \"$producer\"},\n",
    "    {\"$group\": {\"_id\": \"$producer\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "]\n",
    "import pprint\n",
    "pprint.pprint(list(collection.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create timbre vectors and a target vector with 200 songs from each producer. Create test vectors with 100 songs from each producer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timbre_train_test(collection, train_size, test_size):\n",
    "    \n",
    "    producers = collection.distinct('producer')\n",
    "    timbre_train = []\n",
    "    timbre_test = []\n",
    "    target_train = []\n",
    "    target_test = []\n",
    "    for producer in producers:\n",
    "        train_count = 0\n",
    "        test_count = 0\n",
    "        for song in collection.find({'producer':producer}):\n",
    "            try:\n",
    "                # Add data to training set\n",
    "                if train_count < train_size:\n",
    "                    song_timbre_segments = []\n",
    "                    #songs must have at least 80 segments to be in the analysis\n",
    "                    if len((song['audio_analysis']['segments'])) >= 80:\n",
    "                        for i in range(80):\n",
    "                            song_timbre_segments.append(song['audio_analysis']['segments'][i]['timbre'])\n",
    "                        song_timbre_vector = np.concatenate(song_timbre_segments, axis=0)\n",
    "                    timbre_train.append(song_timbre_vector)\n",
    "                    target_train.append(song['producer'])\n",
    "                    train_count += 1\n",
    "\n",
    "                # Add data to test set\n",
    "                elif test_count < test_size:\n",
    "                    song_timbre_segments = []\n",
    "                    #songs must have at least 80 segments to be in the analysis\n",
    "                    if len((song['audio_analysis']['segments'])) >= 80:\n",
    "                        for i in range(80):\n",
    "                            song_timbre_segments.append(song['audio_analysis']['segments'][i]['timbre'])\n",
    "                        song_timbre_vector = np.concatenate(song_timbre_segments, axis=0)\n",
    "                    timbre_train.append(song_timbre_vector)\n",
    "                    target_train.append(song['producer'])\n",
    "                    test_count += 1\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            \n",
    "    return (timbre_train, timbre_test, target_train, target_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "timbre_train, timbre_test, target_train, target_test = make_timbre_train_test(collection, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8020, 960)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(timbre_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7604f4727782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtimbre_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimbre_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "timbre_train.shape(), timbre_test.shape(), target_train.shape(), target_test.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple triangular kernel and kernel constraints\n",
    "kernel_tri = tf.constant_initializer(kernels.triangle_5())\n",
    "kernel_const = min_max_norm(0.001, None, rate=1, axis=0)\n",
    "kernel_nonneg = non_neg()\n",
    "\n",
    "# TensorFlow expects 4D tensors of shape (samples, rows, cols, channels)\n",
    "# Note that the first index (the sample index out of the batch) is stripped\n",
    "model = keras.Sequential([\n",
    "        # Maxpool the image\n",
    "        keras.layers.MaxPool2D(\n",
    "            input_shape=(512, 512, 1),\n",
    "            pool_size=2,\n",
    "            padding='same',\n",
    "            data_format='channels_last'),\n",
    "\n",
    "        # Convolve the pooled image by the shape kernel(s)\n",
    "        # ??? Use LocallyConnected2D instead?\n",
    "        keras.layers.Conv2D(\n",
    "            filters=5,\n",
    "            kernel_size=(8, 8),\n",
    "            strides=(8, 8),\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            activation='sigmoid',\n",
    "            use_bias=True),\n",
    "            # ??? kernel_initializer=kernel_tri,\n",
    "            # kernel_constraint=kernel_nonneg),\n",
    "        keras.layers.Conv2D(\n",
    "            filters=5,\n",
    "            kernel_size=(8, 8),\n",
    "            strides=(8, 8),\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            activation='sigmoid',\n",
    "            use_bias=True),\n",
    "        # Flatten\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        # Basic Dense layer\n",
    "        keras.layers.Dense(\n",
    "            units=25,\n",
    "            activation=None,\n",
    "            # kernel_constraint=kernel_nonneg,\n",
    "            use_bias=True),\n",
    "\n",
    "        # Activation layer\n",
    "        keras.layers.PReLU(),\n",
    "\n",
    "        # Reshape & output\n",
    "        keras.layers.Reshape((5, 5))\n",
    "        ])\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = keras.optimizers.Adadelta()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "if (__name__ == '__main__'):\n",
    "    assert len(sys.argv) == 3, 'Pass me both the training and save filepaths!'\n",
    "    # XXX Testing constants - Remove\n",
    "    try:\n",
    "        TRAINING_SET = sys.argv[1]\n",
    "        SAVE_PATH = sys.argv[2]\n",
    "    except IndexError:\n",
    "        print('Pass me both the training set and save filepaths!')\n",
    "        TRAINING_SET = '../data/train_set_01.pkl'\n",
    "        SAVE_PATH = '../models/saved_model_01.h5'\n",
    "#        sys.exit()\n",
    "\n",
    "    # Load the training set from the pickled ImageBundle\n",
    "    train_bundle = pickle.load(open(TRAINING_SET, 'rb'))\n",
    "    train_X = train_bundle.images\n",
    "    train_y = train_bundle.tri_list\n",
    "\n",
    "    # IN: (samples, rows, cols, channels)\n",
    "    IN_SHAPE = train_X.shape\n",
    "    # OUT: (samples, shape_idx, shape_attrs, channels)\n",
    "    OUT_SHAPE = train_y.shape\n",
    "    # Initialize the training set\n",
    "\n",
    "    # Fit the model to the training ImageBundle\n",
    "    model.fit(\n",
    "        train_X,\n",
    "        train_y[:, :, :, 0],\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        batch_size=5)\n",
    "\n",
    "    # Write model config to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open('../models/model_config.yaml', 'w') as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "\n",
    "    # Save model\n",
    "    model.save(SAVE_PATH, overwrite=True, include_optimizer=True)\n",
    "    print('\\nModel saved at: %s' % SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
