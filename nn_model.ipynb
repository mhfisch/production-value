{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Neural Network to Predict Record Producer from Featurized Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Spotify's Audio Analysis contains a feature called `timbre` which contains information about the qualities of sound that are not found in pitch. From Spotify\n",
    "\n",
    ">*Timbre is the quality of a musical note or sound that distinguishes different types of musical instruments, or voices. It is a complex notion also referred to as sound color, texture, or tone quality, and is derived from the shape of a segmentâ€™s spectro-temporal surface, independently of pitch and loudness. The timbre feature is a vector that includes 12 unbounded values roughly centered around 0. Those values are high level abstractions of the spectral surface, ordered by degree of importance.*\n",
    "\n",
    "I believe that a producer's ***Signature Sound*** can be found in these timbre vectors.\n",
    "\n",
    "I will use `TensorFlow.keras` to create a Convolutional Neural Network that will categorically predict record producer from audio snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Builds the neural network model\n",
    "\"\"\"\n",
    "\n",
    "# Standard Imports\n",
    "from matplotlib.pyplot import imread, imshow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.constraints import min_max_norm, non_neg\n",
    "# import kernels\n",
    "# from artist import CustomImage, ImageBundle\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MongoDB\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "# Access/Initiate Database\n",
    "db = client['producer_db']\n",
    "# Access/Initiate Table\n",
    "tab = db['songs']\n",
    "collection = db.tab\n",
    "\n",
    "# Authorize Spotify API\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "client_id = os.environ['SPOTIFY_CLIENT_ID']\n",
    "client_secret = os.environ['SPOTIFY_CLIENT_SECRET']\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Maxwell/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(12, 80, 1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten(input_shape = (12,80,1)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(32, activation='relu'))\n",
    "# model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (9, 3), (3, 9), (3, 3, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "\n",
    "b = np.concatenate([a,a,a], axis = 0)\n",
    "c = np.concatenate([a,a,a], axis = 1)\n",
    "d = np.stack([a,a,a], axis = 2)\n",
    "\n",
    "a.shape, b.shape, c.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George Martin',\n",
       " 'Dr. Dre',\n",
       " 'Rick Rubin',\n",
       " 'Brian Eno',\n",
       " 'Stock Aitken Waterman',\n",
       " 'Paul Epworth',\n",
       " 'Pete Rock']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.distinct('producer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Rick Rubin', 'count': 2039},\n",
      " {'_id': 'Dr. Dre', 'count': 1498},\n",
      " {'_id': 'George Martin', 'count': 1420},\n",
      " {'_id': 'Pete Rock', 'count': 1252},\n",
      " {'_id': 'Brian Eno', 'count': 924},\n",
      " {'_id': 'Paul Epworth', 'count': 478},\n",
      " {'_id': 'Stock Aitken Waterman', 'count': 436}]\n"
     ]
    }
   ],
   "source": [
    "from bson.son import SON\n",
    "pipeline = [\n",
    "    {\"$unwind\": \"$producer\"},\n",
    "    {\"$group\": {\"_id\": \"$producer\", \"count\": {\"$sum\": 1}}},\n",
    "    {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
    "]\n",
    "import pprint\n",
    "pprint.pprint(list(collection.aggregate(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8047, 0.25338635516341496)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2039+1498+1420+1252+924+478+436), 2039/(2039+1498+1420+1252+924+478+436)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create timbre vectors and a target vector with 200 songs from each producer. Create test vectors with 100 songs from each producer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timbre_train_test(collection, train_size, test_size):\n",
    "    \"\"\"\n",
    "    THIS FUNCTION IS BAD BECAUSE IT DOES NOT RANDOMLY SELECT SAMPLES\n",
    "    \"\"\"\n",
    "    \n",
    "    producers = collection.distinct('producer')\n",
    "    print(producers)\n",
    "    timbre_train = []\n",
    "    timbre_test = []\n",
    "    target_train = []\n",
    "    target_test = []\n",
    "    for producer in producers:\n",
    "        print('Producer: {}'.format(producer))\n",
    "        train_count = 0\n",
    "        test_count = 0\n",
    "        for song in collection.find({'producer':producer}):\n",
    "            try:\n",
    "                # Add data to training set\n",
    "                if train_count < train_size:\n",
    "                    song_timbre_segments = []\n",
    "                    #songs must have at least 80 segments to be in the analysis\n",
    "                    if len((song['audio_analysis']['segments'])) >= 80:\n",
    "                        for i in range(80):\n",
    "                            song_timbre_segments.append(song['audio_analysis']['segments'][i]['timbre'])\n",
    "                        song_timbre_vector = np.concatenate(song_timbre_segments, axis=0)\n",
    "                    timbre_train.append(song_timbre_vector)\n",
    "                    target_train.append(song['producer'])\n",
    "                    train_count += 1\n",
    "#                     print('Ct: {}\\t\\tAdded song {} by {}'.format(train_count,song['track'],song['artist']))\n",
    "\n",
    "                # Add data to test set\n",
    "                elif test_count < test_size:\n",
    "                    song_timbre_segments = []\n",
    "                    #songs must have at least 80 segments to be in the analysis\n",
    "                    if len((song['audio_analysis']['segments'])) >= 80:\n",
    "                        for i in range(80):\n",
    "                            song_timbre_segments.append(song['audio_analysis']['segments'][i]['timbre'])\n",
    "                        song_timbre_vector = np.concatenate(song_timbre_segments, axis=0)\n",
    "                    timbre_test.append(song_timbre_vector)\n",
    "                    target_test.append(song['producer'])\n",
    "                    test_count += 1\n",
    "#                     print('Ct: {}\\t\\tAdded song {} by {}'.format(test_count,song['track'],song['artist']))\n",
    "\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                continue\n",
    "                \n",
    "    timbre_train = np.array(timbre_train)\n",
    "    timbre_test = np.array(timbre_test)\n",
    "    target_train = np.array(target_train)\n",
    "    target_test = np.array(target_test)\n",
    "    return (timbre_train, timbre_test, target_train, target_test)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['George Martin', 'Dr. Dre', 'Rick Rubin', 'Brian Eno', 'Stock Aitken Waterman', 'Paul Epworth', 'Pete Rock']\n",
      "Producer: George Martin\n",
      "Producer: Dr. Dre\n",
      "Producer: Rick Rubin\n",
      "Producer: Brian Eno\n",
      "Producer: Stock Aitken Waterman\n",
      "Producer: Paul Epworth\n",
      "Producer: Pete Rock\n"
     ]
    }
   ],
   "source": [
    "timbre_train, timbre_test, target_train, target_test = make_timbre_train_test(collection, 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1400, 960), (700, 960), (1400,), (700,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timbre_train.shape, timbre_test.shape, target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 10, 78, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 39, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 37, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 93,063\n",
      "Trainable params: 93,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Brian Eno', 'Dr. Dre', 'George Martin', 'Paul Epworth', 'Pete Rock',\n",
       "       'Rick Rubin', 'Stock Aitken Waterman'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.get_dummies(target_train).values\n",
    "producer_vector = pd.get_dummies(target_train).columns\n",
    "\n",
    "producer_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 12, 80, 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timbre_train.reshape(1400, 12, 80, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1400/1400 [==============================] - 2s 1ms/sample - loss: 0.0960 - acc: 0.9671\n",
      "Epoch 2/20\n",
      "1400/1400 [==============================] - 1s 751us/sample - loss: 0.0768 - acc: 0.9750\n",
      "Epoch 3/20\n",
      "1400/1400 [==============================] - 1s 751us/sample - loss: 0.0911 - acc: 0.9714\n",
      "Epoch 4/20\n",
      "1400/1400 [==============================] - 1s 749us/sample - loss: 0.0670 - acc: 0.9750\n",
      "Epoch 5/20\n",
      "1400/1400 [==============================] - 1s 748us/sample - loss: 0.0347 - acc: 0.9871\n",
      "Epoch 6/20\n",
      "1400/1400 [==============================] - 1s 761us/sample - loss: 0.0292 - acc: 0.9893\n",
      "Epoch 7/20\n",
      "1400/1400 [==============================] - 1s 748us/sample - loss: 0.0318 - acc: 0.9864\n",
      "Epoch 8/20\n",
      "1400/1400 [==============================] - 1s 772us/sample - loss: 0.0750 - acc: 0.9786\n",
      "Epoch 9/20\n",
      "1400/1400 [==============================] - 1s 742us/sample - loss: 0.2394 - acc: 0.9171\n",
      "Epoch 10/20\n",
      "1400/1400 [==============================] - 1s 759us/sample - loss: 0.2553 - acc: 0.9186\n",
      "Epoch 11/20\n",
      "1400/1400 [==============================] - 1s 745us/sample - loss: 0.2011 - acc: 0.9286\n",
      "Epoch 12/20\n",
      "1400/1400 [==============================] - 1s 748us/sample - loss: 0.1522 - acc: 0.9421\n",
      "Epoch 13/20\n",
      "1400/1400 [==============================] - 1s 752us/sample - loss: 0.0467 - acc: 0.9800\n",
      "Epoch 14/20\n",
      "1400/1400 [==============================] - 1s 733us/sample - loss: 0.0399 - acc: 0.9850\n",
      "Epoch 15/20\n",
      "1400/1400 [==============================] - 1s 750us/sample - loss: 0.0373 - acc: 0.9829\n",
      "Epoch 16/20\n",
      "1400/1400 [==============================] - 1s 782us/sample - loss: 0.0416 - acc: 0.9793\n",
      "Epoch 17/20\n",
      "1400/1400 [==============================] - 1s 775us/sample - loss: 0.0586 - acc: 0.9779\n",
      "Epoch 18/20\n",
      "1400/1400 [==============================] - 1s 749us/sample - loss: 0.0288 - acc: 0.9879\n",
      "Epoch 19/20\n",
      "1400/1400 [==============================] - 1s 749us/sample - loss: 0.0221 - acc: 0.9850\n",
      "Epoch 20/20\n",
      "1400/1400 [==============================] - 1s 746us/sample - loss: 0.0464 - acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb625c1550>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(timbre_train.reshape(-1,12,80,1), train_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 1s 762us/sample - loss: 5.9679 - acc: 0.2771\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(timbre_test.reshape(-1,12,80,1), pd.get_dummies(target_test).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple triangular kernel and kernel constraints\n",
    "kernel_tri = tf.constant_initializer(kernels.triangle_5())\n",
    "kernel_const = min_max_norm(0.001, None, rate=1, axis=0)\n",
    "kernel_nonneg = non_neg()\n",
    "\n",
    "# TensorFlow expects 4D tensors of shape (samples, rows, cols, channels)\n",
    "# Note that the first index (the sample index out of the batch) is stripped\n",
    "model = keras.Sequential([\n",
    "        # Maxpool the image\n",
    "        keras.layers.MaxPool2D(\n",
    "            input_shape=(512, 512, 1),\n",
    "            pool_size=2,\n",
    "            padding='same',\n",
    "            data_format='channels_last'),\n",
    "\n",
    "        # Convolve the pooled image by the shape kernel(s)\n",
    "        # ??? Use LocallyConnected2D instead?\n",
    "        keras.layers.Conv2D(\n",
    "            filters=5,\n",
    "            kernel_size=(8, 8),\n",
    "            strides=(8, 8),\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            activation='sigmoid',\n",
    "            use_bias=True),\n",
    "            # ??? kernel_initializer=kernel_tri,\n",
    "            # kernel_constraint=kernel_nonneg),\n",
    "        keras.layers.Conv2D(\n",
    "            filters=5,\n",
    "            kernel_size=(8, 8),\n",
    "            strides=(8, 8),\n",
    "            padding='same',\n",
    "            data_format='channels_last',\n",
    "            activation='sigmoid',\n",
    "            use_bias=True),\n",
    "        # Flatten\n",
    "        keras.layers.Flatten(),\n",
    "\n",
    "        # Basic Dense layer\n",
    "        keras.layers.Dense(\n",
    "            units=25,\n",
    "            activation=None,\n",
    "            # kernel_constraint=kernel_nonneg,\n",
    "            use_bias=True),\n",
    "\n",
    "        # Activation layer\n",
    "        keras.layers.PReLU(),\n",
    "\n",
    "        # Reshape & output\n",
    "        keras.layers.Reshape((5, 5))\n",
    "        ])\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = keras.optimizers.Adadelta()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "if (__name__ == '__main__'):\n",
    "    assert len(sys.argv) == 3, 'Pass me both the training and save filepaths!'\n",
    "    # XXX Testing constants - Remove\n",
    "    try:\n",
    "        TRAINING_SET = sys.argv[1]\n",
    "        SAVE_PATH = sys.argv[2]\n",
    "    except IndexError:\n",
    "        print('Pass me both the training set and save filepaths!')\n",
    "        TRAINING_SET = '../data/train_set_01.pkl'\n",
    "        SAVE_PATH = '../models/saved_model_01.h5'\n",
    "#        sys.exit()\n",
    "\n",
    "    # Load the training set from the pickled ImageBundle\n",
    "    train_bundle = pickle.load(open(TRAINING_SET, 'rb'))\n",
    "    train_X = train_bundle.images\n",
    "    train_y = train_bundle.tri_list\n",
    "\n",
    "    # IN: (samples, rows, cols, channels)\n",
    "    IN_SHAPE = train_X.shape\n",
    "    # OUT: (samples, shape_idx, shape_attrs, channels)\n",
    "    OUT_SHAPE = train_y.shape\n",
    "    # Initialize the training set\n",
    "\n",
    "    # Fit the model to the training ImageBundle\n",
    "    model.fit(\n",
    "        train_X,\n",
    "        train_y[:, :, :, 0],\n",
    "        epochs=50,\n",
    "        verbose=1,\n",
    "        batch_size=5)\n",
    "\n",
    "    # Write model config to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open('../models/model_config.yaml', 'w') as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "\n",
    "    # Save model\n",
    "    model.save(SAVE_PATH, overwrite=True, include_optimizer=True)\n",
    "    print('\\nModel saved at: %s' % SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some notes on Models:\n",
    "\n",
    "### Model 1: Flatten -> 64 -> 7:\n",
    "\n",
    "    Made a pretty good model. Train accuracy ~65%. Test accuracy 35%\n",
    "    \n",
    "### Model 2: Flatten -> 64 -> 32 -> 7\n",
    "\n",
    "    Crazy overfitting. Training accuracy ~90% and highly variable. Test accuracy ~30%\n",
    "    \n",
    "### Model 3: Flatten -> 64 -> 32 -> 12 -> 7\n",
    "\n",
    "    Training Accuracy stays around 15-20% for some reason. About the same as randomly guesssing. Test ~15%. A non-model.\n",
    "    \n",
    "### Model 4: Flatten -> 32 -> 7\n",
    "\n",
    "    Train: 88%, Test: 38%  THIS ONE IS GOOD\n",
    "    \n",
    "### Model 5: Flatten -> 12 -> 7\n",
    "\n",
    "    Train and Test: 15%\n",
    "    \n",
    "### Model 6: Flatten -> 32 -> 32 -> 7\n",
    "\n",
    "    Overfit: Train 84%, Test 27%\n",
    "\n",
    "### Simple Model: Flatten -> 7\n",
    "\n",
    "    Train 57% Test 28%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_timbre_train_test(collection, test_size = 0.25, random_state = 440):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        collection: Mongo DB collection\n",
    "        test_size: between 0 and 1, fraction of data in test set.\n",
    "        random_state: random state for sklearn train_test_split\n",
    "        \n",
    "    Outputs:\n",
    "        X_train, X_test, y_train, y_test, y_columns\n",
    "        y_columns is the labels associated with the columns of y\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "                    \n",
    "    for song in collection.find():\n",
    "        try:\n",
    "            song_timbre_segments = []\n",
    "            #songs must have at least 80 segments to be in the analysis\n",
    "            if len((song['audio_analysis']['segments'])) >= 80:\n",
    "                for i in range(80):\n",
    "                    song_timbre_segments.append(song['audio_analysis']['segments'][i]['timbre'])\n",
    "                song_timbre_vector = np.concatenate(song_timbre_segments, axis=0)\n",
    "            X.append(song_timbre_vector)\n",
    "            y.append(song['producer'])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    y_one_hot = pd.get_dummies(y).values\n",
    "    y_columns = pd.get_dummies(y).columns\n",
    "    X = X.reshape(-1,12,80,1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,y_one_hot, test_size = test_size, random_state = random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, y_columns = better_timbre_train_test(collection, test_size = 0.3, random_state = 440 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(12, 80, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten(input_shape = (12,80,1)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "# model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Maxwell/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "7948/7948 [==============================] - 8s 975us/sample - loss: 2.5237 - acc: 0.1856\n",
      "Epoch 2/20\n",
      "7948/7948 [==============================] - 7s 854us/sample - loss: 2.0490 - acc: 0.2402\n",
      "Epoch 3/20\n",
      "7948/7948 [==============================] - 7s 856us/sample - loss: 1.9826 - acc: 0.2714\n",
      "Epoch 4/20\n",
      "7948/7948 [==============================] - 7s 909us/sample - loss: 1.9422 - acc: 0.2846\n",
      "Epoch 5/20\n",
      "7948/7948 [==============================] - 7s 903us/sample - loss: 1.9194 - acc: 0.2913\n",
      "Epoch 6/20\n",
      "7948/7948 [==============================] - 8s 948us/sample - loss: 1.8862 - acc: 0.2971\n",
      "Epoch 7/20\n",
      "7948/7948 [==============================] - 7s 929us/sample - loss: 1.8690 - acc: 0.3076\n",
      "Epoch 8/20\n",
      "7948/7948 [==============================] - 7s 940us/sample - loss: 1.8458 - acc: 0.3129\n",
      "Epoch 9/20\n",
      "7948/7948 [==============================] - 7s 920us/sample - loss: 1.8203 - acc: 0.3240\n",
      "Epoch 10/20\n",
      "7948/7948 [==============================] - 7s 931us/sample - loss: 1.7906 - acc: 0.3339\n",
      "Epoch 11/20\n",
      "7948/7948 [==============================] - 7s 906us/sample - loss: 1.7613 - acc: 0.3461\n",
      "Epoch 12/20\n",
      "7948/7948 [==============================] - 7s 923us/sample - loss: 1.7057 - acc: 0.3678\n",
      "Epoch 13/20\n",
      "7948/7948 [==============================] - 7s 897us/sample - loss: 1.6747 - acc: 0.3816\n",
      "Epoch 14/20\n",
      "7948/7948 [==============================] - 7s 908us/sample - loss: 1.6544 - acc: 0.3830\n",
      "Epoch 15/20\n",
      "7948/7948 [==============================] - 7s 884us/sample - loss: 1.5968 - acc: 0.4132\n",
      "Epoch 16/20\n",
      "7948/7948 [==============================] - 7s 885us/sample - loss: 1.5498 - acc: 0.4249\n",
      "Epoch 17/20\n",
      "7948/7948 [==============================] - 7s 901us/sample - loss: 1.5054 - acc: 0.4451\n",
      "Epoch 18/20\n",
      "7948/7948 [==============================] - 7s 890us/sample - loss: 1.4720 - acc: 0.4614\n",
      "Epoch 19/20\n",
      "7948/7948 [==============================] - 7s 882us/sample - loss: 1.3988 - acc: 0.4886\n",
      "Epoch 20/20\n",
      "7948/7948 [==============================] - 7s 900us/sample - loss: 1.3405 - acc: 0.5073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3fd81e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3407/3407 [==============================] - 1s 362us/sample - loss: 2.4210 - acc: 0.2416\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the full dataset so far (~8000 songs, 7 producers), we get:\n",
    "\n",
    "Flatten - 64 - 7:\n",
    "    Train: 41%, Test: 36%\n",
    "    \n",
    "Flatten - 32 - 7:\n",
    "    Train: 38%, Test: 32%\n",
    "    \n",
    "Hella convolutions:\n",
    "    Train: 73%, Test: 34%\n",
    "    \n",
    "    \n",
    "Note: Currently guessing majority class yields 25% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 2.4521757e-24, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 3.4583623e-15, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
